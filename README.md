# Improving Answer Type Classification Quality Through Combined Question Answering Datasets

## Abstract

Understanding what a person is asking via a question is one of the first steps that humans use to find the answer. 
The same is true for Question Answering (QA) systems. 
Hence, the quality of the expected answer type classifier (EAT) has a direct influence on QA quality. 
Many research papers are aiming at improving short text classification quality, however, there is a lack of focus on the impact of training data characteristics on the classification quality as well as effective reuse of datasets through their augmentation and combination.
In this work, we propose an approach of analyzing and improving the EAT classification quality via a combination of existing QA datasets. 
We provide 4 new question classification datasets based on several well-known QA datasets as well as the approach to unify its class taxonomy.
We made a sufficient amount of experiments to demonstrate several valuable insights related to the impact of training data characteristics on the classification quality.
Additionally, an embedding-based approach for automatic data labeling error detection is demonstrated.

## Quick Links

* Full Paper (TBD)
* [Derived Datasets for Expected Answer Type classification]()
* [Experimental Results]()
* [Labeling Error Analysis Results]()

## Cite

TBD