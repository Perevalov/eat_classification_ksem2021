{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"  # specify which GPU(s) to be used\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import mlflow\n",
    "\n",
    "EXPERIMENT_NAME = 'EAT Prediction'\n",
    "mlflow.set_tracking_uri(\"http://0.0.0.0:41250\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "import time\n",
    "import gc\n",
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import transformers\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import Callback \n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_encode(texts, tokenizer, maxlen=512):\n",
    "    enc_di = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=maxlen\n",
    "    )\n",
    "    \n",
    "    return np.array(enc_di['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(transformer, max_len=512, hidden_dim=32, n_classes=3):\n",
    "    assert n_classes > 2 # only multiclass\n",
    "    \n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    \n",
    "    out = Dense(n_classes, activation='sigmoid')(cls_token)\n",
    "    \n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_steps, train_dataset, model):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss', \n",
    "        verbose=1,\n",
    "        patience=1,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    train_history = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=n_steps,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    return model, train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(ids, test_dataset, y_true_encoded, model):\n",
    "    y_pred_encoded = np.argmax(\n",
    "        model.predict(test_dataset, verbose=1),\n",
    "        axis=1)\n",
    "    \n",
    "    assert len(y_true_encoded) == len(y_pred_encoded)\n",
    "    \n",
    "    f1 = f1_score(y_true_encoded, y_pred_encoded, average='weighted')\n",
    "    precision = precision_score(y_true_encoded, y_pred_encoded, average='weighted')\n",
    "    recall = recall_score(y_true_encoded, y_pred_encoded, average='weighted')\n",
    "    accuracy = accuracy_score(y_true_encoded, y_pred_encoded)\n",
    "    \n",
    "    # getting correctly and incorrectly classified questions\n",
    "    results = list()\n",
    "    for i in range(len(y_true_encoded)):\n",
    "        if y_pred_encoded[i] != y_true_encoded[i]:\n",
    "            results.append('+')\n",
    "        else:\n",
    "            results.append('-')\n",
    "            \n",
    "    df = pd.DataFrame.from_dict({'id': ids, 'result': results, 'true': y_true_encoded, 'pred': y_pred_encoded})\n",
    "    \n",
    "    return f1, precision, recall, accuracy, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Available GPUs: ['/device:GPU:0', '/device:GPU:1'] --------------\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(\"---------- Available GPUs:\", get_available_gpus(), \"--------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 8 * len(get_available_gpus())\n",
    "MAX_LEN = 128\n",
    "MODEL = 'bert-base-cased'\n",
    "\n",
    "TRAIN_LIST = ['LC-QuAD',\n",
    "                'QALD',\n",
    "                'CogComp',\n",
    "                'WebQuestions',\n",
    "                'SimpleQuestions',\n",
    "                'LC-QuAD+QALD',\n",
    "                'LC-QuAD+CogComp',\n",
    "                'LC-QuAD+WebQuestions',\n",
    "                'LC-QuAD+SimpleQuestions',\n",
    "                'QALD+CogComp',\n",
    "                'QALD+WebQuestions',\n",
    "                'QALD+SimpleQuestions',\n",
    "                'CogComp+WebQuestions',\n",
    "                'CogComp+SimpleQuestions',\n",
    "                'WebQuestions+SimpleQuestions',\n",
    "                'LC-QuAD+QALD+CogComp',\n",
    "                'LC-QuAD+QALD+WebQuestions',\n",
    "                'LC-QuAD+QALD+SimpleQuestions',\n",
    "                'LC-QuAD+CogComp+WebQuestions',\n",
    "                'LC-QuAD+CogComp+SimpleQuestions',\n",
    "                'LC-QuAD+WebQuestions+SimpleQuestions',\n",
    "                'QALD+CogComp+WebQuestions',\n",
    "                'QALD+CogComp+SimpleQuestions',\n",
    "                'QALD+WebQuestions+SimpleQuestions',\n",
    "                'CogComp+WebQuestions+SimpleQuestions',\n",
    "                'LC-QuAD+QALD+CogComp+WebQuestions',\n",
    "                'LC-QuAD+QALD+CogComp+SimpleQuestions',\n",
    "                'LC-QuAD+QALD+WebQuestions+SimpleQuestions',\n",
    "                'LC-QuAD+CogComp+WebQuestions+SimpleQuestions',\n",
    "                'QALD+CogComp+WebQuestions+SimpleQuestions',\n",
    "                'LC-QuAD+QALD+CogComp+WebQuestions+SimpleQuestions']\n",
    "\n",
    "TEST_LIST = ['LC-QuAD', 'QALD', 'CogComp', 'WebQuestions', 'SimpleQuestions'] \n",
    "\n",
    "# classes\n",
    "types = ['Event', 'Place', 'Colour', 'SportsSeason', 'Name', 'DateTime', 'Device', 'Activity', 'Number', 'Biomolecule', 'Disease', 'Food', 'Work', 'AnatomicalStructure', 'Currency', 'TopicalConcept', 'Species', 'Boolean', 'Award', 'TimePeriod', 'Altitude', 'Agent', 'Language', 'Flag', 'Holiday', 'ChemicalSubstance', 'MeanOfTransportation', 'Medicine', 'EthnicGroup', 'PersonFunction', 'String', 'List']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the real tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline():\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(types)\n",
    "        \n",
    "    for train_name in TRAIN_LIST:\n",
    "        train_df = pd.read_csv(f\"../../data/UnifiedSubclassDBpedia/{train_name}-train.csv\", sep=';')\n",
    "        \n",
    "        encoded_y_train = encoder.transform(train_df.type)\n",
    "        dummy_y_train = np_utils.to_categorical(encoded_y_train)\n",
    "        \n",
    "        x_train = regular_encode(train_df.questionText.astype(str), tokenizer, maxlen=MAX_LEN)\n",
    "        \n",
    "        train_dataset = (\n",
    "            tf.data.Dataset\n",
    "            .from_tensor_slices((x_train, dummy_y_train))\n",
    "            .repeat()\n",
    "            .shuffle(2048)\n",
    "            .batch(BATCH_SIZE)\n",
    "            .prefetch(AUTO)\n",
    "        )\n",
    "        \n",
    "        transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
    "        model = build_model(transformer_layer, max_len=MAX_LEN, n_classes=len(types))\n",
    "        n_steps = x_train.shape[0] // BATCH_SIZE\n",
    "        \n",
    "        print(f\"--------- START TRAINING {train_name} ------------\")\n",
    "        start = time.time()\n",
    "        ########\n",
    "        model, train_history = train_model(n_steps, train_dataset, model)\n",
    "        ########\n",
    "        train_time = time.time() - start\n",
    "        print(f\"--------- END TRAINING {train_name}------------\")\n",
    "        \n",
    "        with open(f\"../../data/experimental_metadata/{train_name}.hist\", 'w') as file:\n",
    "            json.dump(train_history.history, file, indent=4)\n",
    "        \n",
    "        for test_name in TEST_LIST:\n",
    "            test_df = pd.read_csv(f\"../../data/UnifiedSubclassDBpedia/{test_name}-test.csv\", sep=';')\n",
    "        \n",
    "            x_test = regular_encode(test_df.questionText.astype(str), tokenizer, maxlen=MAX_LEN)\n",
    "            y_true_encoded = encoder.transform(test_df.type)\n",
    "            \n",
    "            test_dataset = (\n",
    "                tf.data.Dataset\n",
    "                .from_tensor_slices(x_test)\n",
    "                .batch(BATCH_SIZE)\n",
    "            )\n",
    "            \n",
    "            print(f\"--------- START EVALUATION {test_name} ------------\")\n",
    "            start = time.time()\n",
    "            #########\n",
    "            f1, precision, recall, accuracy, df_meta = evaluate_model(\n",
    "                test_df.question,\n",
    "                test_dataset,\n",
    "                y_true_encoded,\n",
    "                model\n",
    "            )\n",
    "            #########\n",
    "            inference_time = time.time() - start\n",
    "            print(f\"--------- END EVALUATION {test_name} ------------\")\n",
    "            \n",
    "            df_meta.to_csv(\n",
    "                f\"../../data/experimental_metadata/TRAIN:{train_name} || TEST:{test_name}.csv\",\n",
    "                sep=';',\n",
    "                index=False\n",
    "            )\n",
    "            \n",
    "            with mlflow.start_run():\n",
    "                mlflow.log_param(\"Train Data\", train_name)\n",
    "                mlflow.log_param(\"Test Data\", test_name)\n",
    "                mlflow.log_param(\"EPOCHS\", EPOCHS)\n",
    "                mlflow.log_param(\"BATCH_SIZE\", BATCH_SIZE)\n",
    "                mlflow.log_param(\"MAX_LEN\", MAX_LEN)\n",
    "                mlflow.log_param(\"MODEL\", MODEL)\n",
    "                mlflow.log_param(\"Metadata Path\", f\"/home/aperevalov/hs-anhalt-master-thesis/data/experimental_metadata/TRAIN:{train_name} || TEST:{test_name}.csv\")\n",
    "                mlflow.log_param(\"History Path\", f\"/home/aperevalov/hs-anhalt-master-thesis/data/experimental_metadata/{train_name}.hist\")\n",
    "                mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "                mlflow.log_metric(\"Precision\", precision)\n",
    "                mlflow.log_metric(\"Recall\", recall)\n",
    "                mlflow.log_metric(\"F1 Score\", f1)\n",
    "                mlflow.log_metric(\"Training Time\", train_time)\n",
    "                mlflow.log_metric(\"Inference Time\", inference_time)\n",
    "                \n",
    "                print(\"F1\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- START TRAINING LC-QuAD ------------\n",
      "Epoch 1/8\n",
      "116/116 [==============================] - 19s 161ms/step - loss: 2.1942 - accuracy: 0.2662\n",
      "Epoch 2/8\n",
      "116/116 [==============================] - 19s 161ms/step - loss: 1.8247 - accuracy: 0.3739\n",
      "Epoch 3/8\n",
      "116/116 [==============================] - 19s 160ms/step - loss: 1.2745 - accuracy: 0.5873\n",
      "Epoch 4/8\n",
      "116/116 [==============================] - 19s 160ms/step - loss: 0.6905 - accuracy: 0.8766\n",
      "Epoch 5/8\n",
      "116/116 [==============================] - 19s 160ms/step - loss: 0.5149 - accuracy: 0.9100\n",
      "Epoch 6/8\n",
      "116/116 [==============================] - 18s 159ms/step - loss: 0.3512 - accuracy: 0.9461\n",
      "Epoch 7/8\n",
      "116/116 [==============================] - 18s 159ms/step - loss: 0.2894 - accuracy: 0.9542\n",
      "Epoch 8/8\n",
      "116/116 [==============================] - 18s 159ms/step - loss: 0.2256 - accuracy: 0.9628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- END TRAINING LC-QuAD------------\n",
      "--------- START EVALUATION LC-QuAD ------------\n",
      "29/29 [==============================] - 2s 59ms/step\n",
      "--------- END EVALUATION LC-QuAD ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.8669185364743346\n",
      "--------- START EVALUATION QALD ------------\n",
      "9/9 [==============================] - 0s 53ms/step\n",
      "--------- END EVALUATION QALD ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.6534527194962831\n",
      "--------- START EVALUATION CogComp ------------\n",
      "78/78 [==============================] - 5s 60ms/step\n",
      "--------- END EVALUATION CogComp ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.4140262284160063\n",
      "--------- START EVALUATION WebQuestions ------------\n",
      " 55/172 [========>.....................] - ETA: 7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-29bc503c7850>\", line 1, in <module>\n",
      "    pipeline()\n",
      "  File \"<ipython-input-10-e0dbe04b49fc>\", line 56, in pipeline\n",
      "    model\n",
      "  File \"<ipython-input-6-d92cf7f350e3>\", line 3, in evaluate_model\n",
      "    model.predict(test_dataset, verbose=1),\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 130, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1599, in predict\n",
      "    tmp_batch_outputs = predict_function(iterator)\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 814, in _call\n",
      "    results = self._stateful_fn(*args, **kwds)\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\n",
      "    cancellation_manager=cancellation_manager)\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 550, in call\n",
      "    ctx=ctx)\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/posixpath.py\", line 428, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/home/aperevalov/miniconda3/lib/python3.6/posixpath.py\", line 86, in join\n",
      "    for b in map(os.fspath, p):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
